---
title: "Untitled"
output: html_document
date: '2022-11-17'
---


December 21, 2020 Other Open Access
BERT-CRel: Improved Biomedical Word Embeddings in the Transformer Era
https://zenodo.org/record/4383195#.Y1wDBb7MJhE

BERT-CRel is a transformer model for fine-tuning biomedical word embeddings that are jointly learned along with concept embeddings using a pre-training phase with fastText and a fine-tuning phase with a transformer setup. The goal is to provide high quality pre-trained biomedical embeddings that can be used in any `downstream task` by the research community. The corpus used for BERT-CRel contains biomedical citations from PubMed and the concepts are from the Medical Subject Headings (MeSH codes) terminology used to index citations. 

```{r}
library(dplyr)
file_path = '/home/jtimm/pCloudDrive/nlp/BERT-CRel-meshes.vec'
## file_path <- 'https://zenodo.org/record/4383195/files/BERT-CRel-meshes.vec?download=1'

options(timeout = 500)
lines <- readLines(file_path)
embeddings <- matrix(nrow = 45015, ncol = 396)
ns <- vector()

for (i in 2:length(lines)) {
    line <- lines[[i]]
    values <- strsplit(line, " ")[[1]]
    label <- values[[1]]
    embeddings[i-1, ] <- as.double(values[-1])
    ns[i-1] <- label
}

rownames(embeddings) <- toupper(gsub('mesh', '', ns))

ebs1 <- data.table::setDT(embeddings |> data.frame(), 
                          keep.rownames = 'DescriptorUI')[] 

meshE <- ebs1 |> filter(grepl('^D', DescriptorUI))
scrE <- ebs1 |> filter(grepl('^C', DescriptorUI))

setwd('/home/jtimm/pCloudDrive/GitHub/git-projects/mesh-builds/data')
saveRDS(meshE, 'data_mesh_embeddings.rds')
saveRDS(scrE, 'data_scr_embeddings.rds')
```




